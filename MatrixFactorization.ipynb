{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vACTmYVfOfSz",
        "outputId": "d006ecd6-5b04-469c-9f9a-0b3d7c807be8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LYUAu2f7Olu1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection, metrics, preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZKAd7x4nS9Gt"
      },
      "outputs": [],
      "source": [
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94wSklNIbS92"
      },
      "source": [
        "Load the JSON input into a pandas data frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "z-mQdCT7SIUJ"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "data = []\n",
        "with open('/content/drive/MyDrive/CSE272/Movies_and_TV.json', 'r') as file:\n",
        "    for line in file:\n",
        "        data.append(json.loads(line))\n",
        "\n",
        "df = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P44m0XsjcKyM",
        "outputId": "6dd2662b-9605-40a3-aea4-e478ca9cf77b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['overall', 'verified', 'reviewTime', 'reviewerID', 'asin', 'style',\n",
              "       'reviewerName', 'reviewText', 'summary', 'unixReviewTime', 'vote',\n",
              "       'image'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiI3L0O0bbGE"
      },
      "source": [
        "Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fPzm1oeecAY6"
      },
      "outputs": [],
      "source": [
        "df = df.drop(['verified', 'reviewTime', 'style', 'reviewerName', 'reviewText', 'summary', 'unixReviewTime', 'vote', 'image'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYwyopOPcYgm",
        "outputId": "4b20d150-4da7-44c2-982a-46d3d3b4e71b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['overall', 'reviewerID', 'asin'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "V6uMRt4rbSZZ"
      },
      "outputs": [],
      "source": [
        "# remove all users with less than 5 reviews\n",
        "user_counts = df.reviewerID.value_counts()\n",
        "valid_users = user_counts[user_counts >= 5].index\n",
        "\n",
        "df = df[df.reviewerID.isin(valid_users)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "14opGPG8Fo5E"
      },
      "outputs": [],
      "source": [
        "lbl_user = preprocessing.LabelEncoder()\n",
        "lbl_product = preprocessing.LabelEncoder()\n",
        "df.reviewerID = lbl_user.fit_transform(df.reviewerID.values)\n",
        "df.asin = lbl_product.fit_transform(df.asin.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MVlAJVoob-Ox"
      },
      "outputs": [],
      "source": [
        "# define train and test data frames\n",
        "grouped_df = df.groupby(df.reviewerID)\n",
        "\n",
        "train_df = grouped_df.sample(frac=0.8, random_state=1)\n",
        "\n",
        "test_df = df.drop(train_df.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlwnFdrFekxm"
      },
      "outputs": [],
      "source": [
        "# save data frames to save time\n",
        "train_df.to_csv('/content/drive/MyDrive/CSE272/train_df.csv')\n",
        "test_df.to_csv('/content/drive/MyDrive/CSE272/test_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ExSkOBBIDKYR"
      },
      "outputs": [],
      "source": [
        "# load data frames to save time\n",
        "df_train = pd.read_csv('/content/drive/MyDrive/CSE272/train_df.csv')\n",
        "df_valid = pd.read_csv('/content/drive/MyDrive/CSE272/test_df.csv')\n",
        "df = pd.concat([df_train,df_valid])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "91QtcCvgSJjc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from torchvision.io import read_image\n",
        "\n",
        "class MoviesTVDataset(Dataset):\n",
        "    def __init__(self, users, products, ratings):\n",
        "        self.users = users\n",
        "        self.products = products\n",
        "        self.ratings = ratings\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.users)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        users = self.users[idx]\n",
        "        products = self.products[idx]\n",
        "        ratings = self.ratings[idx]\n",
        "\n",
        "        return {\n",
        "            \"users\": torch.tensor(users, dtype=torch.long),\n",
        "            \"products\": torch.tensor(products, dtype=torch.long),\n",
        "            \"ratings\": torch.tensor(ratings, dtype=torch.long),\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "shO_fS9VSM8P"
      },
      "outputs": [],
      "source": [
        "class MatrixFactorizationModel(nn.Module):\n",
        "    def __init__(self, n_users, n_products):\n",
        "        super().__init__()\n",
        "\n",
        "        self.user_embed = nn.Embedding(n_users, 32)\n",
        "        self.product_embed = nn.Embedding(n_products, 32)\n",
        "        self.user_embed.weight.data.uniform_(0, 0.5)\n",
        "        self.product_embed.weight.data.uniform_(0, 0.5)\n",
        "\n",
        "    def forward(self, users, products, ratings=None):\n",
        "        user_embeds = self.user_embed(users)\n",
        "        product_embeds = self.product_embed(products)\n",
        "        output = torch.diag(torch.mm(user_embeds,torch.transpose(product_embeds,0,1)))\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5ZfwjgswdWP4"
      },
      "outputs": [],
      "source": [
        "train_dataset = MoviesTVDataset(\n",
        "    users=df_train.reviewerID.values,\n",
        "    products=df_train.asin.values,\n",
        "    ratings=df_train.overall.values\n",
        ")\n",
        "\n",
        "valid_dataset = MoviesTVDataset(\n",
        "    users=df_valid.reviewerID.values,\n",
        "    products=df_valid.asin.values,\n",
        "    ratings=df_valid.overall.values\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcxMpQVedYnI",
        "outputId": "b99567f4-73ed-4a0e-8b39-13505d35f997"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'users': tensor([306465, 215140, 168996,  ..., 292290,  70258, 191584]), 'products': tensor([ 94399,  55707,  98930,  ...,  92474, 133537,  32331]), 'ratings': tensor([5, 2, 1,  ..., 4, 5, 4])}\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                          batch_size=2048,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2) \n",
        "\n",
        "validation_loader = DataLoader(dataset=valid_dataset,\n",
        "                          batch_size=2048,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2) \n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "dataloader_data = next(dataiter)\n",
        "print(dataloader_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLqrcx24wMsa",
        "outputId": "439993dd-3b92-4a5e-af8c-a6ca93b99037"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2902609"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "len(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "lMShrLaYwrN8"
      },
      "outputs": [],
      "source": [
        "from sklearn import model_selection, metrics, preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7ety3WpwSzU1"
      },
      "outputs": [],
      "source": [
        "model = MatrixFactorizationModel(\n",
        "    n_users=df.reviewerID.nunique(),\n",
        "    n_products=df.asin.nunique(),\n",
        ").to(device)\n",
        "\n",
        "loss_func = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hU1HRWRDV4G-"
      },
      "outputs": [],
      "source": [
        "def train_epocs(model, epochs=1, lr=0.01, wd=0.0):\n",
        "    epochs = 1\n",
        "    total_loss = 0\n",
        "    plot_steps, print_steps = 5000, 5000\n",
        "    step_cnt = 0\n",
        "    all_losses_list = [] \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    model.train()\n",
        "    for epoch_i in range(epochs):\n",
        "         for i, train_data in enumerate(train_loader):\n",
        "            output = model(train_data[\"users\"].to(device), \n",
        "                        train_data[\"products\"].to(device)\n",
        "                        ) \n",
        "            \n",
        "            rating = train_data[\"ratings\"].view(len(output), -1).to(torch.float32)\n",
        "\n",
        "            loss = loss_func(output, rating.to(device))\n",
        "            total_loss = total_loss + loss.sum().item()\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            step_cnt = step_cnt + len(train_data[\"users\"])\n",
        "            \n",
        "\n",
        "            if(step_cnt % plot_steps == 0):\n",
        "                print(i)\n",
        "                avg_loss = total_loss/(len(train_data[\"users\"]) * plot_steps)\n",
        "                print(f\"epoch {epoch_i} loss at step: {step_cnt} is {avg_loss}\")\n",
        "                all_losses_list.append(avg_loss)\n",
        "                total_loss = 0 # reset total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlZFQXeQWNRh",
        "outputId": "322d2c12-0343-4b13-f628-2311949f6a91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([2048, 1])) that is different to the input size (torch.Size([2048])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "624\n",
            "epoch 0 loss at step: 1280000 is 0.00014159419650677593\n",
            "1249\n",
            "epoch 0 loss at step: 2560000 is 0.00012659903737949208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([593, 1])) that is different to the input size (torch.Size([593])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ],
      "source": [
        "train_epocs(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9glZV3gsiFlq",
        "outputId": "d2b8da22-5904-451c-918f-2c7ee978fb08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rms: 0.11068885851373923\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "model_output_list = []\n",
        "target_rating_list = []\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, batched_data in enumerate(validation_loader): \n",
        "        model_output = model(batched_data['users'].to(device), \n",
        "                       batched_data[\"products\"].to(device))\n",
        "        \n",
        "        model_output_list.append(model_output.sum().item() / len(batched_data['users']) )\n",
        "\n",
        "\n",
        "        target_rating = batched_data[\"ratings\"]\n",
        "        \n",
        "        target_rating_list.append(target_rating.sum().item() / len(batched_data['users']))\n",
        "\n",
        "        # print(f\"model_output: {model_output}, target_rating: {target_rating}\")\n",
        "\n",
        "\n",
        "# squared If True returns MSE value, if False returns RMSE value.\n",
        "rms = mean_squared_error(target_rating_list, model_output_list, squared=False)\n",
        "print(f\"rms: {rms}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clWg2KAd1QaB",
        "outputId": "5a32deb2-a708-4023-f9a2-47bb9a72c45f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mae: 0.10611124339995893\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "mae = mean_absolute_error(target_rating_list, model_output_list)\n",
        "print(f\"mae: {mae}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# a dict that stores a list of predicted rating and actual rating pair for each user \n",
        "user_est_true = defaultdict(list)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, batched_data in enumerate(validation_loader): \n",
        "        users = batched_data['users']\n",
        "        products = batched_data['products']\n",
        "        ratings = batched_data['ratings']\n",
        "        \n",
        "        model_output = model(batched_data['users'].to(device), batched_data[\"products\"].to(device))\n",
        "\n",
        "        for i in range(len(users)):\n",
        "            user_id = users[i].item()\n",
        "            product_id = products[i].item() \n",
        "            pred_rating = model_output[i].item()\n",
        "            true_rating = ratings[i].item()\n",
        "            \n",
        "            user_est_true[user_id].append((pred_rating, true_rating))            "
      ],
      "metadata": {
        "id": "p6f79YV3KaTq"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    precisions = dict()\n",
        "    recalls = dict()\n",
        "\n",
        "    k=1\n",
        "    threshold=3.5\n",
        "    lens = []\n",
        "    for uid, user_ratings in user_est_true.items():\n",
        "\n",
        "        # Sort user ratings by estimated value. \n",
        "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
        "        lens.append(len(user_ratings))\n",
        "\n",
        "        # get the number of actual relevant item\n",
        "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
        "\n",
        "        # get the number of recommended item that are predicted relevent and within topk\n",
        "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
        "\n",
        "        # get the number of recommented item that' is also actually relevant within topk\n",
        "        n_rel_and_rec_k = sum(\n",
        "            ((true_r >= threshold) and (est >= threshold))\n",
        "            for (est, true_r) in user_ratings[:k]\n",
        "        )\n",
        "\n",
        "        # Precision@K: Proportion of recommended items that are relevant\n",
        "        # When n_rec_k is 0, Precision is undefined. We here set it to 0.\n",
        "\n",
        "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
        "\n",
        "        # Recall@K: Proportion of relevant items that are recommended\n",
        "        # When n_rel is 0, Recall is undefined. We here set it to 0.\n",
        "\n",
        "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0"
      ],
      "metadata": {
        "id": "3qQXq-k2NHBF"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "counts = Counter(lens)\n",
        "print(len(lens))\n",
        "print(counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILlwUxQffM4l",
        "outputId": "730a2de8-7afb-4f83-91c2-c0ac400e45e8"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311221\n",
            "Counter({1: 168848, 2: 79519, 3: 26707, 4: 12405, 5: 6776, 6: 4163, 7: 2828, 8: 1898, 9: 1445, 10: 1071, 11: 854, 12: 633, 13: 489, 14: 439, 15: 340, 16: 279, 17: 241, 18: 196, 19: 186, 21: 153, 20: 148, 22: 128, 23: 114, 24: 96, 26: 78, 27: 77, 28: 70, 25: 67, 30: 58, 29: 52, 31: 52, 32: 37, 36: 35, 33: 34, 41: 32, 38: 29, 34: 29, 42: 26, 40: 25, 46: 24, 37: 22, 39: 22, 44: 21, 47: 21, 35: 18, 49: 16, 45: 14, 48: 13, 43: 13, 51: 12, 56: 11, 60: 11, 52: 11, 53: 11, 59: 10, 55: 10, 54: 9, 50: 9, 57: 8, 62: 8, 73: 8, 72: 7, 71: 7, 65: 7, 83: 7, 81: 6, 61: 6, 90: 6, 63: 5, 80: 5, 70: 5, 76: 5, 77: 5, 64: 4, 95: 4, 82: 4, 117: 4, 74: 4, 85: 4, 66: 4, 78: 4, 69: 4, 68: 4, 58: 4, 79: 4, 134: 3, 106: 3, 125: 3, 178: 3, 124: 3, 153: 3, 127: 3, 88: 3, 93: 3, 75: 3, 89: 3, 91: 2, 107: 2, 231: 2, 120: 2, 142: 2, 97: 2, 67: 2, 139: 2, 150: 2, 333: 2, 187: 2, 105: 2, 175: 2, 86: 2, 183: 2, 113: 2, 96: 2, 84: 2, 143: 2, 135: 2, 92: 2, 111: 2, 851: 1, 242: 1, 458: 1, 152: 1, 161: 1, 224: 1, 241: 1, 267: 1, 169: 1, 306: 1, 218: 1, 435: 1, 427: 1, 101: 1, 403: 1, 164: 1, 176: 1, 252: 1, 381: 1, 230: 1, 162: 1, 147: 1, 170: 1, 110: 1, 181: 1, 302: 1, 144: 1, 122: 1, 151: 1, 99: 1, 282: 1, 225: 1, 133: 1, 131: 1, 115: 1, 353: 1, 198: 1, 234: 1, 370: 1, 129: 1, 168: 1, 160: 1, 137: 1, 226: 1, 179: 1, 154: 1, 346: 1, 87: 1, 409: 1, 213: 1, 173: 1, 323: 1, 200: 1, 98: 1, 211: 1, 171: 1, 365: 1, 205: 1, 104: 1, 195: 1, 100: 1, 156: 1, 140: 1, 116: 1, 119: 1, 118: 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_valid.reviewerID.nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXEvjH8_f6-M",
        "outputId": "4771b488-53f9-4098-a211-89754bf3f963"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "311221"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision and recall can then be averaged over all users\n",
        "print(f\"precision @ {k}: {sum(prec for prec in precisions.values()) / len(precisions)}\")\n",
        "\n",
        "print(f\"recall @ {k} : {sum(rec for rec in recalls.values()) / len(recalls)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2facdXwOex7",
        "outputId": "1f5c0c3b-ae58-4941-dde9-ad67765a026e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision @ 1: 0.6478322478238936\n",
            "recall @ 1 : 0.46834764927961425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline recommendation list algorithm"
      ],
      "metadata": {
        "id": "H-38jWBaQRPY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "zyEUxHZl8Ucw",
        "outputId": "fef8caaa-ef61-4565-c551-9cf1facfe01c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-01b7eedca87d>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtop_batch_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtop_batch_products\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecs_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             model_output = model(batched_data[\"users\"].to(device), \n\u001b[1;32m     22\u001b[0m                         batched_data[\"products\"].to(device))\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1292\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1295\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "all_users = df.reviewerID.unique()\n",
        "user_subset = np.random.choice(all_users, 175, replace=False)\n",
        "all_products = df.asin.unique()\n",
        "\n",
        "with open(\"/content/drive/MyDrive/CSE272/recs.txt\", 'w') as file:\n",
        "    for num_users, user in enumerate(user_subset):\n",
        "        dummy_ratings = [0] * len(all_products)\n",
        "        users = [user] * len(all_products)\n",
        "        recs_dataset = MoviesTVDataset(\n",
        "            users=users,\n",
        "            products=all_products,\n",
        "            ratings=dummy_ratings\n",
        "        )\n",
        "        recs_loader = DataLoader(dataset=recs_dataset,\n",
        "                          batch_size=2048,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2) \n",
        "        top_batch_values = []\n",
        "        top_batch_products= []\n",
        "        for i, batched_data in enumerate(recs_loader): \n",
        "            model_output = model(batched_data[\"users\"].to(device), \n",
        "                        batched_data[\"products\"].to(device))\n",
        "            indices = np.argsort(model_output.cpu().detach().numpy())[-10:]\n",
        "            cur_values = sorted(model_output.cpu().detach().numpy())[-10:]\n",
        "            cur_products = [all_products[i] for i in indices]\n",
        "            top_batch_products.extend(cur_products)\n",
        "            top_batch_values.extend(cur_values)\n",
        "        top_batch_indices = np.argsort(top_batch_values)[-10:]\n",
        "        top_products = [top_batch_products[i] for i in top_batch_indices]\n",
        "        original_user = lbl_user.inverse_transform([user])\n",
        "        original_products = lbl_product.inverse_transform(top_products)\n",
        "        line = f'{original_user[0]} {original_products[0]} {original_products[1]} {original_products[2]} {original_products[3]} {original_products[4]} {original_products[5]} {original_products[6]} {original_products[7]} {original_products[8]} {original_products[9]}\\n'\n",
        "        file.write(line)\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4jcU7hI9Dh_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}